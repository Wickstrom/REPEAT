{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyOLwf1N2Wza6yK+Z/oHN0hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability\n","This notebook illustrates the basic usage of REPEAT, a new method for representation learning explainablity with improved uncertainty estimation. If you are running this notebook on Google Colab, remember to enable GPU support to speed up computation.\n","\n","REPEAT treats each pixel in an image as a Bernoulli random variable that is either important or unimportant to the representation of the image. From these Bernoulli random variables we can directly estimate the importance of a pixel and its associated certainty, thus enabling users to ascertain certainty in pixel importance.\n","\n","This notebook consists of 6 cells of code:\n","\n","1. Install and import packages: installs and imports the necessary packages.\n","2. Data transformations: A selection of functions that transforms the image into the shape and format expected by the feature extractor.\n","3. Load and plot example image: Loads an example image, transforms it, and plots it.\n","4. Feature extractor: Defines a function that loads a pretrained ResNet18 feature extractor.\n","5. Code for REPEAT: A class that implement the REPEAT methodology.\n","6. Run REPEAT on example image: Loads feature extractor, runs REPEAT, and plots the results of the analysis.\n","\n"],"metadata":{"id":"EtNeXtNjxNQG"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"m7ktlgqnwODi"},"outputs":[],"source":["#@title Install and import packages\n","\n","!pip install relax-xai\n","\n","import torch\n","import scipy.misc\n","import torchvision\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","from relax_xai.relax import RELAX\n","from skimage.filters import threshold_triangle, threshold_otsu, threshold_mean"]},{"cell_type":"code","source":["#@title Data transformations\n","\n","IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD = [0.229, 0.224, 0.225]\n","\n","class ToDevice(torch.nn.Module):\n","    \"\"\"\n","    Sends the input object to the device specified in the\n","    object's constructor by calling .to(device) on the object.\n","    \"\"\"\n","    def __init__(self, device):\n","        super().__init__()\n","        self.device = device\n","\n","    def forward(self, img):\n","        return img.to(self.device)\n","\n","    def __repr__(self) -> str:\n","        return f\"{self.__class__.__name__}(device={self.device})\"\n","\n","def unsqeeze_image(input_image: torch.Tensor) -> torch.Tensor:\n","    return input_image.unsqueeze(0)\n","\n","\n","def imagenet_image_transforms(device: str, new_shape_of_image: int = 224):\n","    \"\"\"\n","    Returns transformations that takes a torch tensor and transforms it into a new tensor\n","    of size (1, C, new_shape_of_image, new_shape_of_image), normalizes the image according\n","    to the statistics from the Imagenet dataset, and puts the tensor on the desired device.\n","    \"\"\"\n","    transform = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Resize((new_shape_of_image, new_shape_of_image)),\n","        torchvision.transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","        torchvision.transforms.Lambda(unsqeeze_image),\n","        ToDevice(device),\n","    ])\n","\n","    return transform\n","\n","\n","def imsc(img, *args, quiet=False, lim=None, interpolation='lanczos', **kwargs):\n","    r\"\"\"Rescale and displays an image represented as a img.\n","    The function scales the img :attr:`im` to the [0 ,1] range.\n","    The img is assumed to have shape :math:`3\\times H\\times W` (RGB)\n","    :math:`1\\times H\\times W` (grayscale).\n","    Args:\n","        img (:class:`torch.Tensor` or :class:`PIL.Image`): image.\n","        quiet (bool, optional): if False, do not display image.\n","            Default: ``False``.\n","        lim (list, optional): maximum and minimum intensity value for\n","            rescaling. Default: ``None``.\n","        interpolation (str, optional): The interpolation mode to use with\n","            :func:`matplotlib.pyplot.imshow` (e.g. ``'lanczos'`` or\n","            ``'nearest'``). Default: ``'lanczos'``.\n","    Returns:\n","        :class:`torch.Tensor`: Rescaled image img.\n","    \"\"\"\n","    if isinstance(img, Image.Image):\n","        img = torchvision.transforms.pil_to_tensor(img)\n","    handle = None\n","    with torch.no_grad():\n","        if not lim:\n","            lim = [img.min(), img.max()]\n","        img = img - lim[0]  # also makes a copy\n","        img.mul_(1 / (lim[1] - lim[0]))\n","        img = torch.clamp(img, min=0, max=1)\n","        if not quiet:\n","            bitmap = img.expand(3,\n","                                *img.shape[1:]).permute(1, 2, 0).cpu().numpy()\n","    return bitmap"],"metadata":{"cellView":"form","id":"lfJs_rAVxCqR","executionInfo":{"status":"ok","timestamp":1710401270918,"user_tz":-60,"elapsed":5,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title Load and plot example image\n","\n","example_image = scipy.misc.face()\n","example_image = imagenet_image_transforms('cuda')(example_image)\n","\n","plt.figure(1)\n","plt.imshow(imsc(example_image.squeeze()))\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"cellView":"form","id":"kp0dYe5wx7qY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Feature extractor\n","\n","def load_resnet18_encoder() -> nn.Module:\n","\n","    resnet18 = torchvision.models.resnet18(weights=\"DEFAULT\")\n","    modules = list(resnet18.children())[:-1]\n","    encoder = nn.Sequential(*modules, nn.Flatten())\n","    encoder.eval()\n","\n","    return encoder"],"metadata":{"cellView":"form","id":"yZgs86FcxMl5","executionInfo":{"status":"ok","timestamp":1710401272730,"user_tz":-60,"elapsed":10,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#@title Code for REPEAT\n","\n","\n","class REPEAT(nn.Module):\n","    \"\"\"\n","    This class implement REPEAT, a new method for represenationa learning\n","    explainability. REPEAT treats each pixel in an image as a Bernoulli random\n","    variable that is either important or unimportant to the representation of the image.\n","    From these Bernoulli random variables we can directly estimate the importance\n","    of a pixel and its associated certainty, thus enabling users to ascertain\n","    certainty in pixel importance.\n","\n","    Parameters\n","    ----------\n","    input_image\n","        Input image to be explained.\n","    encoder\n","        Encoder that transforms the input image into a new representation\n","    num_repeats\n","        How many times to repat the RELAX calculation\n","    num_batches\n","        Number of batches with masks to generate\n","    batch_size\n","        The size of each batch of masks\n","    explanation_threshold\n","        Method for thresholding explanation into important and non-important pixels\n","    \"\"\"\n","    def __init__(self,\n","                 input_image: torch.Tensor,\n","                 encoder: nn.Module,\n","                 num_repeats: int = 10,\n","                 batch_size: int = 100,\n","                 num_batches: int = 10,\n","                 explanation_threshold: str = 'mean'\n","                 ) -> None:\n","        super().__init__()\n","\n","        self.input_image = input_image\n","        self.num_repeats = num_repeats\n","        self.num_batches = num_batches\n","        self.batch_size = batch_size\n","\n","        self.device = input_image.device\n","        self.shape = tuple(input_image.shape[2:])\n","\n","        self.probability_of_importance = torch.zeros(self.shape, device=self.device)\n","        self.uncertainty = torch.zeros(self.shape, device=self.device)\n","\n","        self.encoder = encoder\n","        self.explanation_threshold = explanation_threshold\n","\n","        self.THRESHOLD_METHODS = {\n","            'mean': threshold_mean,\n","            'otsu': threshold_triangle,\n","            'triangle': threshold_otsu,\n","        }\n","\n","    def forward(self) -> None:\n","\n","      for _ in range(self.num_repeats):\n","\n","          with torch.no_grad():\n","            relax = RELAX(self.input_image, self.encoder, self.num_batches, self.batch_size)\n","            relax.forward()\n","\n","            threshold_val = self.threshold_method(relax.importance, explanation_threshold=self.explanation_threshold)\n","\n","            weight = relax.importance / relax.importance.max()\n","            self.probability_of_importance += weight * (relax.importance > threshold_val)\n","\n","      self.probability_of_importance /= self.num_repeats\n","      self.uncertainty = self.probability_of_importance * (1 - self.probability_of_importance)\n","\n","      return None\n","\n","    def threshold_method(self, explanation: torch.Tensor, explanation_threshold: str) -> torch.Tensor:\n","        return self.THRESHOLD_METHODS[explanation_threshold](explanation.numpy(force=True))\n","\n"],"metadata":{"cellView":"form","id":"HDwdqkjGyts3","executionInfo":{"status":"ok","timestamp":1710401272730,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@title Run REPEAT on example image\n","\n","\n","encoder = load_resnet18_encoder().to('cuda')\n","repeat = REPEAT(example_image, encoder)\n","repeat.forward()\n","\n","\n","plt.figure(1)\n","plt.subplot(131)\n","plt.imshow(imsc(example_image.squeeze()))\n","plt.axis('off')\n","plt.subplot(132)\n","plt.imshow(imsc(example_image.squeeze()))\n","plt.imshow(repeat.probability_of_importance.numpy(force=True), alpha=0.75, cmap='bwr')\n","plt.axis('off')\n","plt.subplot(133)\n","plt.imshow(imsc(example_image.squeeze()))\n","plt.imshow(repeat.uncertainty.numpy(force=True), alpha=0.75, cmap='bwr')\n","plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"cellView":"form","id":"os9KeJ9Uz1Bp"},"execution_count":null,"outputs":[]}]}